---
title: 15-差分隐私阶段总结03
published: 2024-02-01
description: '本文是对差分隐私相关论文的整理，同时涵盖了重要公式的推导和疑难问题的收集。'
tags: [Differential Privacy, DeepLearning model]
category: '知识总结'
draft: false 
---
# 论文汇总-01

| Title                                                                           | Journal / conference-Year | DP Type   | Privacy Definition                       | Prevention targets                                            | Introduction                                                                                                                      | Trade-Off                                            | Deficiencies                                                      |
| ------------------------------------------------------------------------------- | ------------------------- | --------- | ---------------------------------------- | ------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------- | ----------------------------------------------------------------- |
| DP-CGAN : Differentially Private Synthetic Data and Label Generation            | CVPRW-2019                | Record-DP | - Original Dataet                        | Membership Inference Attacks                                  | 1、基于 CGAN 引入RDP机制<br/>2、训练 D 时，真实数据集 和 生成数据集 分开来计算梯度，再加噪                                                                          | 效用-隐私                                                | 1、需要大量带标记的数据<br/>2、没有对 分类 和 生成 之间的关系做探讨                           |
| Triple Generative Adversarial Networks                                          | TPAMI-2021                | Non-DP    | /                                        | /                                                             | 1、引入分类器 C，拆分 D 的分类任务<br/>2、引入两个 KL 散度等效式，约束 C 和 G 的收敛<br/>3、通过一系列数学证明推导出了结果的收敛性质                                                  | /                                                    | 涉及大量梯度运算，也没有降低GAN的复杂度                                             |
| Semi-Supervised Knowledge Transfer for Deep Learning from Private Training Data | ICLR-2017                 | Class-DP  | - Original Dataet/<br/>- Model Parameter | Membership Inference Attacks<br/><br/>Model Extraction Attack | 1、教师机制从互不相交的原数据集子集中训练<br/>2、学生模型从公开数据集中训练<br/>3、学生从公开数据集中获得输入，向教师聚合机制提问，投票结果加噪 \|                                                 | 1、数据集划分-教师模型的精度<br/>2、投票精度-隐私保证                      | 1、调参复杂<br/>2、学生直接询问，噪声较多<br/>3、投票不可微，DP分析难                        |
| Scalable Private Learning with PATE                                             | ICLR-2018                 | Class-DP  | - Original Dataet/<br/>- Model Parameter | Membership Inference Attacks<br/><br/>Model Extraction Attack | 1、设立教师投票结果的阈值，以及学生自己对回答结果的确信阈值<br/>2、如果学生和教师结果相反，判定值超过阈值，则返回教师分类结果<br/>3、如果回答相同，学生结果高于确信阈值，返回学生分类结果<br/>4、其余不回答，回避了可能导致高噪声、低精度的结果 | 1、数据集划分-教师模型的精度<br/>2、投票精度-隐私保证<br/>3、阈值 T 和 γ 之间的权衡 | 1、调参更复杂<br/>2、给出了学生询问的筛选机制，感觉可以更进一步探索1                            |
| PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees        | ICLR-2019                 | Record-DP | - Original Dataet                        | Membership Inference Attacks                                  | 1、将 D 改写为 PATE 机制<br/>2、学生从生成器中获取训练集<br/>3、学生类似聚合机制，保证梯度可微，反馈给生成器                                                                 | 1、数据集划分-教师模型的精度<br/>2、投票精度-隐私保证                      | 1、学生机制使得教师的投票可微。但失去了PATE 防止”模型窃取攻击“的能力<br/>2、教师投票的标签是布尔值，噪声的影响会较大 |
| DP-SGD vs PATE: Which Has Less Disparate Impact on GANs?                        | /-2021                    | /         | /                                        | /                                                             | 1、比较 PATE-GAN 和 DPWGAN 在三种场景、不同 ε 下的表现                                                                                            | /                                                    | /                                                                 |

# 一、DP-CGAN : Differentially Private Synthetic Data and Label Generation

### 一、提出缘由：

- 针对 DP-GAN 的改进。DP-GAN 只针对于生成合成的数据，但无法附带相应的标签，这使得合成的数据难以应用到监督学习上；

- DPGAN 的质量较差，保持较高数据精度的DPGAN，epsilon 参数往往难以控制在个位数上。

### 二、实现思路：

- 隐私定义：训练用的元敏感数据集。主要针对的是“成员推理攻击“。

- 算法流程：

    - 采用了 RDP Accountant，相比 Moment Accountant 有更紧的上界；

    - 基于 CGAN 的框架引入了高斯噪声机制；

    - 先训练 D 的时候，将“真实数据”和“生成数据”分开计算梯度、裁剪，最后合并再添加噪声，用 SGD 优化。

- Trade off：

    - 和 DPGAN 一样，梯度裁剪、加噪来确保隐私保护。通过裁剪，将梯度的范围控制在 C (也就是分布的敏感度)；

    - 该算法的权衡主要体现在“利用精度来换取隐私保护”；

    - 通过在梯度上的扰动来防止“成员推理攻击”。但对于“模型窃取攻击”（窃取模型的参数去重构训练集的数据）难以发挥作用。因为针对梯度的扰动，并无法防止模型参数泄露后的攻击行为；

    - 综上，可以被归类为 “Record-DP”，

### 三、实现效果：

- 基线方法是 “CGAN with basic DP”，此外还对比了CGAN的方法；

- 比起基线方法，准确度提高了5%，说明对DP的改进是有效果的；

- 但比起CGAN方法，准确度低了4%，这是为了隐私保护而做出的牺牲。

### 四、不足之处：

- 训练 DP-CGAN 需要大量的、带标记的数据，这是一个很高的要求；

- 整体上算是给 CGAN 加入了 renyi accountant 机制，从而使其具备了差分隐私的功能，思路较为简单；

- 没有针对 分类 和 生成 之间的关系，做进一步的探讨。

### 五、启发思想：

- 引入了一个新的训练方向：在 DP 规则下，生成带标签的数据集，从而提高数据的可用性，使其可以用在诸如监督学习这样的任务上；

- 仔细思考一下，DPCGAN 这样的训练方式的合理性是存疑的。最终完全由 D 来判别数据的真伪，但在这个过程中，我们对于生成数据的要求是：①标签分类要准确；②数据的真伪是难辨的。第一个要求本质上是要求“更低的信息熵”，而第二个要求本质上是要求“更高的信息熵”，两者是相悖的。因为没有针对不同的熵要求进行处理，因而最终的训练结果必然是在这两者的之间、存在优化的空间。

---

---

# 二、**Triple Generative Adversarial Networkss**

### 一、提出缘由：

- 许多情况下，只有少部分数据会附带标签，CGAN 的实用性并不强；

- 当 GAN 收敛时，即便是最有判别器都无法区分数据 X 是真还是假，因此具有很高的预测熵。另一方面，对于分类任务，要求最终数据应该被正确分类，因此要求有较低的预测熵。因此，鉴别和分类任务，应该是同一假设空间中的不同点。针对这一点，作者提出了 Triple-GAN 的思路。

### 二、实现思路：

- 隐私定义：本文不涉及隐私保护。

- 算法流程：

    - 引入了两个条件网络：分类器 C 和生成器 G。前者给定真实数据的前提下，生成伪标签；后者在给定真实标签的前提下，生成伪数据；

    - 定义了判别器网络 D：只判别 <数据，标签>对 是否来自真实的标记数据集；

    - 每次循环开始时，分别从 G 、C 和真实分布 data 中采样 $m_g$ 、$m_c$  和 $m_d$ 的数据；

    - 因为引入了新的实体，所以需要重新设计损失函数。先更新 D，针对生成器 G 和分类器 C，采用 α 和 1-α 的格式来平衡：

$$
\nabla_{\theta_d}[\frac{1}{m_d}(\sum_{(x_d,y_d)}logD(x_d,y_d))+\frac{\alpha}{m_c}\sum_{(x_c,y_c)}log(1-D(x_c,y_c))+\frac{1-\alpha}{m_g}\sum_{(x_g,y_g)}log(1-D(x_g,y_g))]
$$

    - 然后计算两个 KL 散度的等效替换体。有需要的话，再计算正则化表达式：

$$
R_c=-\frac{1}{m_d}\sum_{(x_d,y_d)}log(P_c(y_d|x_d))\;\;\&\;\;R_p=-\frac{1}{m_g}\sum_{(x_g,y_g)}log(P_c(y_g|x_g))
$$

    - 借用这些式子，更新分类器 C：

$$
\nabla_{\theta_c}[\frac{\alpha}{m_c}\sum_{x_c}\sum_{y\in Y}P_c(y|x_c)log(1-D(x_c,y))+R_c+\alpha_pR_p+\alpha_uR_u]
$$

    - 最后再更新生成器 G：

$$
\nabla_{\theta_g}[\frac{1-\alpha}{m_g}\sum_{x_g,y_g}log(1-D(x_g,y_g))]
$$

- Trade off：

    - 作者先证明了 D 会收敛到唯一值 $D(x,y)=\frac{P(x,y)}{P(x,y)+P_\alpha(x,y)}$，其中 $P_\alpha(x,y)=\alpha P_c(x,y)+(1-\alpha)P_g(x,y)$

    - 利用 JS 散度的特性步骤，或者令 D 最终收敛到 1/2，得到如下性质：

$$
V(C,G)\; achieve\;its\;minimum \; value,if\;and\;only\;if\;:P(x,y)=P_\alpha(x,y)=\alpha P_c(x,y)+(1-\alpha)P_g(x,y)
$$

    - 根据这道公式，作者将 $P_g$ 和 $P_c$ 之间的 trade-off 做了解耦。由上式不难看出，当 $P_g$ 或者 $P_c$ 中的一方向真实分布 P 靠近时，另一方也会跟着接近。也就是说，两者不存在竞争关系；

    - 为了防止最终收敛时，$P_g$ 和 $P_c$ 的收敛不一致、这两者和真实分布 P 不一致，因此引入了两个 KL 散度的等效替换量来使这三个分布趋同。

### 三、实现效果：

- 数据集为 MNIST、SVHN、CIFAR、Tiny ImageNet

- 基线方法设置为了：improved-GAN, mean teacher classifier。此外，还与一些主流的 GAN 进行 了对比（DCGAN、WGAN，CGAN-DP）

- 在超过 10 个基准测试上的表现都明显优于大部分半监督学习的方法。此外，Triple-GAN 还有个优势，仅使用 8% 的标签数据，在 CIFAR10上，IS 和 FID 的测试值就能和使用全标签训练的 CGAN-DP 相当。

### 四、不足之处：

- 不难发现，在训练的过程中涉及了大量的梯度运算、KL散度值计算、正则化计算…计算的复杂度明显上升了；

- 虽然作者证明了引入新的感知器 C 后，并不会增加训练的复杂度。但是同样的，也没有降低训练的难度。GAN 的训练本身还是比较复杂的。

### 五、启发思想：

- 这篇论文从学习任务的本质出发，探讨了分类、生成两种任务对于预测熵的不同期望，从而总结出了将两者划分成不同实体、分别进行约束的方法；

- 对于那些要求生成带标签数据的 DP 的任务而言，Triple-GAN 做了一个比较大的工作，那就是将分类和生成拆分了开来。在进行隐私分析时，可以更加清晰地针对不同实体进行判别，而非只是单独地在 D 上统一加噪。

---

---

# 三、Semi-Supervised Knowledge Transfer for Deep Learning from Private Training Data

### 一、提出缘由：

- 机器学习的模型中会隐式地存储一些训练数据，这本质上是由于模型的泛化能力不足导致的；

- 之前的工作提出的隐私保护方法，大多是针对具体的机器学习设计独特的 DP 机制。缺少一种适用于广泛模型的 DP 机制；

- 以前的 DP 机制，虽然能够防范“成员推理攻击”，但是面对“模型窃取攻击”往往没有多少作用。

### 二、实现思路：

- 隐私定义：该方法的目的是防范“白盒”和“黑盒”攻击，因而隐私既包括了“原始隐私数据集”的内容，也包括了“模型的参数”。

- 算法流程：

    - 首先将原始的隐私数据集划分为互不相交的子集，然后针对每个子集，用各自的方法训练教师模型。教师模型的训练是在不考虑隐私保护的前提下进行的；

    - 针对教师模型进行聚合。针对每次查询，每个教师根据自己模型的结果进行投票，在最终的分类结果上添加噪声，实现隐私保护。在添加噪声后的标签票数中，选择票数最多的那个输出；

    - 隐私保护的部分由“Moment Accountant”给出。每次添加噪声时，将更新 Moment Accountant；

    - 为了防止“模型窃取攻击”，训练一个“学生”模型。它将从公共数据集中获得输入，将输入提交给聚合模型，并获得添加噪声之后的输出作为结果。学生将利用这些输入输出进行训练；

    - 针对学生的知识迁移训练，文章中采用了 GAN 的方法；

    - 最后输出学生模型。

- Trade off：

    - 数据集的划分和教师模型的训练。如果教师的数量太多，那么每个教师被划分到的原始数据集就偏少了，这就容易导致单个教师模型的训练结果会不太理想，有可能会影响到最终的精确度；

    - 投票的精度和隐私噪声的权衡。添加的噪声如果太大，有可能会逆转教师投票的结果，降低精度。但噪声如果太小，在教师们的共识不太强烈的时候，容易泄露隐私。

### 三、实现效果：

- 测数据集为 MNIST 和 SVHN；

- 在 MNIST 上，相对于不添加噪声的基线模型，学生模型的精确度相当高，仅低了1%左右；

- 在 SVHN 上，ε 和 询问量 都较低的情况下，学生模型的精确度相较基线模型低了10个百分点。提高参数后，可以做到比基线模型低1.5%；

- 应该注意到，PATE 模型不仅能防范“成员推理攻击”，由于应用了学生模型来迁移教师们的知识，所以还具备防范“模型窃取攻击”的能力；

- PATE 应该算是 “Class-DP”。

### 四、不足之处：

- 涉及的模型参数和实体很多，调参很复杂；

- 学生每次拿到一个公开数据集，不论质量，就去询问聚合机制，这显然会增加噪声的扰动；

- 涉及到了投票的过程，隐私分析的难度较高。

### 五、启发思想：

- 知识迁移过程可以有效地防止“模型窃取攻击”；

- PATE 也可以用作一个效率很高的分类器，或者说，判别器。如果可以和 GAN 组合，说不定可以提高 GAN 模型的效用。

---

---

# 四、Scalable Private Learning with PATE

### 一、提出缘由：

- PATE 机制在此之前只应用于简单的任务，缺少现实的、大规模的评估工作；

- 针对 PATE 机制，提出了一种改进的措施，利用高斯噪声、阈值机制，提高了 PATE 机制在隐私、效用和实用性上的表现。

### 二、实现思路：

- 隐私定义：同 PATE 机制一样，隐私定义既包含了 “原始的隐私数据”，也包含了“模型的参数”。

- 算法流程：在原先的 PATE 机制上做了一些改进措施。具体来讲包括如下内容：

    - 隐私保护采样时，采用高斯噪声来代替拉普拉斯噪声。因为高斯噪声尾部减少的速度更快，这增加了在差分隐私的前提下，教师聚合产生机制可以产生正确答案的概率；

    - 使用 renyi 机制代替 moment accountant，从而每次添加噪声时可以获得更紧的上界；

    - 针对教师聚合机制，设立一个阈值 T，当 $max_i\{n_j(x)\}+N(0,\sigma_1^2) \geq T$ 时，选择输出 $max_i\{n_j(x)\}+N(0,\sigma_2^2) \geq T$ 。否则认为教师之间并没有达成足够的共识，此时如果输出结果，不仅需要添加的噪声会变多，精度也会遭受影响；

    - 针对“教师—学生”之间的互动机制，同样设立一个阈值 γ。

        - 首先从学生自己的模型处获得预测值 p(x)，然后评估“学生-老师”之间的共识。如果学生不同意老师，那么评价两者的差值是否超过阈值 T，判定是否接受教师的答案：

$$
if \;max_j\{n_j(x)-M*p_j(x)\}+N(0,\sigma_1^2)\geq T,\;then: \\return \;arg\;max_j\{n_j(x)+N(0,\sigma_2^2)\}
$$

        - 如果没有超过阈值，则再判定学生是否对自己的答案确信：

$$
else \; if \; max\{p_i(x)\} > \gamma,\;then:\\return \;arg\;max_j \;p_j(x)
$$

        - 如果上面两个回答都是否定的，则认为①学生自己对自己的回答没有信心；②教师之间的共识也不够高。给这样的问题添加标签，既容易降低精度，也需要添加更多的噪声量。因此，针对这类的情况，直接拒绝回答。

- Trade off：

    - 本文是对 PATE 机制的改进。因而原原本本地保留了 PATE 机制的两个 trade-off：①数据集的划分和教师模型的训练；②投票的精度和隐私噪声的权衡；

    - 相比起来，本文引入了两个阈值 T 和 γ。这两个阈值直接关乎模型的接受程度和训练效果，也直接评价着添加噪声的程度和规模。因而还存在阈值 T 和 γ 之间的权衡：是否调低 T 的值，让教师接管更多的训练，降低隐私保护，但相对提高了精度；还是调高 T、降低 γ 的值，让学生具备更高的自主性、从而提高隐私保护，但降低了精度。

### 三、实现效果：

- 测试数据集为 MNIST, SVHN 和 UCI 数据库，还有 Glyph分类任务；

- 对比模型是原 PATE 机制的 LNMax 模型，基线模型是 无-DP 的分类模型；

- 在 MNIST, SVHN, Adult 上，Confident-GNMax在 ε 更小的前提下，精度比 LNMax 更高。在 Glyph 测试中，尽管相比 无-DP 的基线测试，DP模型的准确率都低了8%-10%，但模型的彼此之间，Interactive-GNMax 在精度介于 Confident-GNMax 和 LNMAX 的状况下，ε 可以做到 0.8的程度。

### 四、不足之处：

- 阈值 T 和 γ 的选择直接关乎了模型的效果，也在一定程度上评价着噪声的程度和规模。但对于 T 和 γ 的平衡，缺少相关的关系式，只能通过不断的测试来寻找最优解。

### 五、启发思想：

- 本文方法的提出，是针对“教师-学生之间的查询”做细化分析的结果。具体来讲，面对一个分类任务，学生-教师之间有“赞同”、“分歧”两种可能的结果。此外，即便结果相同，不同的投票、预测结果，添加的噪声量也会有差别，带来的精度损失也不能一概而论。

- 作者选择了最简单粗暴的方法：“学生和教师共识不一致时，之差高于阈值 T，则接受教师的分类”，“共识一致时，学生预测值高于阈值 γ，则接受学生的分类”。其他所有的情况都排除在外。相当于把所有需要添加高噪声、降低精度的查询请求都除外了。

---

---

# 五、**PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees**

### 一、提出缘由：

- 在差分隐私的前提下，生成合成数据集，如果考虑多维联合分布，那将是一个 NP-Hard 问题。因而需要借助 GAN 这样的方法来生成近似的结果；

- 基于原始数据的汇总统计或基于特定领域知识的合成数据，只能适用于低维特征空间，不能提供差分隐私保证；

- 之前的 GAN 只关注离散变量的生成，对于混合类型的变量缺少支持；

- PATE 机制相比一般的感知器，效用和隐私保护方面做得更好。

### 二、实现思路：

- 隐私定义：需要注意的是，虽然本模型用到了 PATE 机制，但只是作为鉴别器的一部分，最终发布的还是生成器。因而隐私保护只能保护“原始数据集”，不能保护“模型参数”。只能预防“成员推理攻击”，无法预防“模型窃取攻击”。

- 算法流程：

    - 用 PATE 机制代替 D，引入了 k 个教师鉴别器以及 1  个学生鉴别器 S 。从而形成了：教师模型被训练，用来改善他们相对于 G 的损失；生成器被训练，用来改善相对于学生 S 的损失；学生 S 被训练，用来改善相对于教师的损失；

    - 针对教师机制的训练相对容易：每个教师都可以从它被划分到的数据集里进行训练，以及从生成器里获取伪数据进行判别。每个教师的损失函数可以写成下面这样：

$$
L_T^i(\theta_T^i)=-[\sum_{u\in D_i}log\;T_i(u;\theta_T^i)+\sum_{j=1}^nlog(1-T_i(G(z_j);\theta_T^i)]
$$

    - 针对学生机制的训练相对复杂了很多。这是因为在 PATE 机制中，针对学生的训练是由公开的数据集来训练的，但在这里并没有公开的数据集以供学生训练。因此必须用一种新的方法来训练学生。一种方式是，利用生成器生成的数据来训练学生（考虑一般的 GAN 流程，训练 G 时，只考虑 D 对 G 进行评估）。具体来说，首先从 $P_z$ 中采样 n 次，使用生成器生成 n 个数据，将这些数据用 PATE 的教师机制来鉴别，判定真伪。令 $r_j$ 为 n 个数据中教师判定为真的概率，则学生训练的损失函数可以写为;

$$
L_S(\theta_S)=\sum_{j=1}^n r_j\;log\;S(\hat{u}_j;\theta_S)+(1-r_j)log(1-S(\hat{u}_j;\theta_S))
$$

    - 使用 Moment Accountant 来框定添加噪声的上界。

- Trade off：

    - 教师的数量和噪声的影响，这个 trade-off 仍然存在。教师的数量越多，噪声对单个投票造成的影响就越小，但每个教师可以分得的数据量就越少，单个教师模型的精度很差；教师数量越少，每个教师分得的数据量越多，单个教师模型的精度越高，但噪声造成的影响也随之变大；

### 三、实现效果：

- 两种测试思路：①通过合成数据集训练的模型，在真实数据集上的表现是否足够好？②在合成数据集上比较的模型性能差异，和它们在真实数据集上比较的结果是否相似？

- 两个 Kaggle 数据集，两个不同的真实医疗数据集，和两个 UCI 数据集；

- 两个指标：AUROC 和 AUPRC；12个测试模型；对比模型为 DPGAN 和 GAN。

- 基本上 PATE-GAN 的效果介于 GAN 和 DPGAN 中间。但在 ε 特别小的地段， PATE-GAN 和 DPGAN 的效用都出现了较大幅度的衰减。一种可能的解释是，PATE-GAN 中，学生鉴别器只能使用来自生成器的数据进行训练，因此要求一些生成的数据从一开始就比较真实，在 epsilon 较低的情况下，这个任务会很艰难；而 DPGAN 必须在梯度的每个分量中添加噪声，因此在高维中添加的噪声范数会更大，而 PATE-GAN 旨在教师输出中添加噪声，维度通常为1，不依赖于输入数据的维度。这就使得 PATE-GAN 的效用要高于 DPGAN。

### 四、不足之处：

- 在这个模型中，学生模型更像是一个聚合机制。教师投票、加噪后的数据是无法微分的，因而利用学生这个聚合机制来处理微分，同时将梯度传递给 G 来更新。但 PATE 机制本身属于 Class-DP，通过发布学生模型来预防“模型窃取攻击”。但在这里，学生模型属于鉴别器，并没有发布。因此 PATE-GAN 并不具备防备“模型窃取攻击”的能力。

- 直觉上来看，教师的投票机制所处理的标签，是一个布尔值，只有 T 和 F 两种可能的选择，因而噪声的扰动效果可能会比较显著，导致精度上受限。

### 五、启发思想：

- 提出了一种新颖的模型判别方法：①经典方法：在合成数据集上训练的模型，和在真实数据集上训练的模型，两者的性能差距；②新方法：预测模型在合成数据集上的性能排名，和它们在真实数据集上的性能排名进行比较。

- 将 PATE 机制替换了 GAN 中的鉴别器 D，这样做的理由是：① GAN中鉴别器的任务是进行判别，这个过程也可以用分类来理解（分成真、伪两类），因此可以使用 PATE 机制来替换；② DPGAN 类似的训练中，噪声是往梯度中添加的，因而添加的噪声范式直接跟数据的维度相关，在高维部分添加的噪声会较大。而 PATE 机制中，噪声是往教师的投票中添加的，维度通常为 1，这是 PATE 机制的一个优势所在。

---

---

# 六、**DP-SGD vs PATE: Which Has Less Disparate Impact on GANs?**

### 一、提出缘由：

- 比较 DP-SGD 和 PATE （主要由 DP-WGAN 和 PATE-GAN）两种机制在 “隐私-效用的权衡”、“生成类的平衡性”、“鲁棒性”等方面的差异性。

### 二、实验准备

- 比较对象：DP-SGD & PATE

- 比较模型：DP-WAGAN & PATE-GAN

- 比较方面：

    - 低 ε 下的精度表现4

    - 隐私-效用的权衡

    - 鲁棒性

    - 生成类的平衡性

- 实验流程：

    - 首先，由于原始数据集中的类存在轻微的不平衡，超过5000张的图片被移除，以确保每个类别的样本数量均衡。

    - 然后，在数据集中对“8”类进行不平衡处理，有三种不同的处理设置：

        - 少数类：将“8”类的样本数量降低到原始大小的10%或25%，同时保持其他类别的样本平衡。

        - 多数类：不对“8”类进行处理，而是将其他类别的样本数量降低到原始大小的10%或25%。

        - 混合处理：将“8”类的样本数量设置为最大或最小类别的25%，同时以均匀递减的方式随机不平衡处理其他类别。

    - 进行评估

### 三、实验结果（这里直接搬运一下作者的结论部分）

- 少数类：

    - PATEGAN在两种不平衡情况下的表现要好得多。即使在较低的预算条件下，PATEGAN仍保持着数据的分布，召回率的下降也不太明显，并且其标准偏差较低。而DP-WGAN则出现了随机的召回率，这意味着分类器未能学到任何有用的知识，很可能是由于合成数据的质量较差所致；

    - 然而，观察到在不平衡程度为10%的少数类别“8”中，PATE-GAN无法生成任何数字。令人惊讶的是，这种现象在“非DP”情况下也出现了。这可能是因为即使在应用于分类时，PATE在相似的不平衡水平下具有更强的鲁棒性，但老师们未能将被分类为真实数据的“8”样本传递给学生；

    - 当应用差分隐私（DP）时，PATE-GAN的性能实际上会提高。例如，在ε=15和ε=5的情况下，PATE-GAN的结果比“非DP”情况下更好，无论是在数据分布上还是召回率上。这可能是因为教师-判别器接触到的真实数据子集不同，它们学习到的分布也不完全相同，同时投票结果受到噪声的影响，进一步增强了泛化性能。

- 多数类：

    - 对于DP-WGAN模型，在所有的下采样数字中，召回率都显著下降，即使在“non-DP”情况下也是如此。而PATE-GAN模型的行为非常稳定；

    - 在数据集大小方面，PATE-GAN生成的数据集更不平衡，生成了更多的“8s”数字，而其他数字的数量较少，这适用于所有的ε预算。但是，对于ε = 15而言，相比于“non-DP”，PATE-GAN的结果更好。当从25%的不平衡增加到10%时，并不会有任何类别“消失”。然而，对于DP-WGAN模型而言，随着不平衡度的增加，性能变得更糟，这表明PATE-GAN模型需要更小的训练数据来捕捉底层分布，并且对不平衡更具鲁棒性；

    - 有趣的是，某些数字的召回率要比其他数字更低（例如，“2”，“5”，“9”），这可以解释为它们在视觉上与“8”相似，但其大小要小得多。

- 混合处理：

    - 在增加隐私保护的情况下，PATE-GAN在大小和召回率方面的变异性/扩散较低，并且在召回率方面的下降较小。作者还清楚地观察到了两种生成模型所展现的相反的大小效应，与（Ganev，Oprisanu和De Cristofaro 2021）类似 - DP-WGAN使得类别更加均衡，即大类别减少，小类别增加，而PATE-GAN进一步加强了不平衡，使得大类别变得更大；

    - 就召回率而言，对于所有的隐私保护预算ε，PATE-GAN的性能在所有类别上略微下降，并且实际上超过了“非-DP”的DP-WGAN。这个观察表明，在不严重不平衡的情况下，PATE框架下的少数群体不会不公平地受到影响。至于DP-WGAN，大小似乎是一个重要因素，对于ε = 15，较小的类别承受了更大的降低。当ε = 0.5时，召回率看起来是随机的。

### 四、实验总结：

- PATE-GAN：

    - 在两种不平衡情况下（少数类和多数类）的表现较好，尤其在较低预算条件下仍能保持数据分布，召回率下降较小。

    - 对于少数类别中10%不平衡程度的情况下，PATE-GAN无法生成类别为“8”的数字，即使在非DP情况下也出现这种现象。

    - 当应用差分隐私（DP）时，PATE-GAN的性能实际上会提高，无论是在数据分布上还是召回率上，这可能是因为投票结果受到噪声的影响，进一步增强了泛化性能。

    - 在混合处理下，增加隐私保护的情况下，PATE-GAN的大小变异性较低，召回率的下降较小，进一步加强了不平衡。

- DP-WGAN：

    - 在多数类的情况下，召回率明显下降，即使在非DP情况下也是如此。相比之下，PATE-GAN模型的行为较为稳定。

    - DP-WGAN生成的数据集更加平衡，但对于某些数字，召回率比其他数字更低，因为它们在视觉上与数字“8”相似但尺寸较小。

    - 在混合处理下，对于ε = 15，较小的类别承受了更大的降低，而且对于所有隐私保护预算ε，召回率看起来是随机的。

### 五、启发思想：

- 为什么 PATE-GAN 会比 DPGAN 有更好的效用？哪怕是在低隐私预算的情况下，也有着更好的表现。

    - 可能的原因：正如上一篇的 PATE-GAN 论文中所述，DPGAN直接在梯度中加噪，因而对于一些高维的数据，添加的噪声也会更多一点。而 PATE 机制直接在投票结果上加噪，维度通常为1，所以在相同 ε 的情况下，PATE机制因为其添加噪声时的上界更紧，效用会更好。

- 为什么 PATE-GAN 会加剧数据集之间的不平衡？

    - 可能的原因：

        - 投票机制引入的不平衡：PATE-GAN使用投票机制来确定最终生成的样本。在投票过程中，如果某个类别的样本数量较少，可能会导致该类别被低估，生成的数据集中缺乏该类别的样本，进而导致数据集的不平衡性。

        - 少数类样本的稀缺性：在不平衡数据集中，少数类别的样本相对较少。由于PATE-GAN的生成过程是基于现有的少数类别样本，如果初始的少数类别样本数量有限，生成的数据集中该类别的样本数量也会较少，进一步加剧了不平衡性。

- 为什么 PATE-GAN 在处理一些不平衡的数据时会崩溃？

    - 可能的原因：正如上面所示的那样，PATE-GAN 具备强鲁棒性，这有可能起到了一定的影响。当不平衡程度设定为10%时，少数类别的样本数量极少，教师网络中可能没有足够的样本表示少数类别。这可能导致教师网络在生成样本时没有充分覆盖少数类别的数字，进而影响了PATE-GAN生成少数类别的数字。
